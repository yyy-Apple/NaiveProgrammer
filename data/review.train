This work studies the predictive uncertainty issue of deep learning models . In particular , this work focuses on the distributional uncertainty which is caused by distributional mismatch between training and test examples . The proposed method is developed based on the existing work called Dirichlet Prior Network ( DPN ) . It aims to address the issue of DPN that its loss function is complicated and makes the optimization difficult . Instead , this paper proposes a new loss function for DPN , which consists of the commonly used cross-entropy loss term and a regularization term . Two loss functions are respectively defined over in-domain training examples and out-of-distribution ( OOD ) training examples . The final objective function is a weighted combination of the two loss functions . Experimental study is conducted on one synthetic dataset and two image datasets ( CIFAR-10 and CIFAR-100 ) to demonstrate the properties of the proposed method and compare its performance with the relevant ones in the literature . The issue researched in this work is of significance because understanding the predictive uncertainty of a deep learning model has its both theoretical and practical value . The motivation , research issues and the proposed method are overall clearly presented . The current recommendation is Weak Reject because the experimental study is not convincing or comprehensive enough . 1 . Although the goal of this work is to deal with the inefficiency issue of the objective function of existing DPN with the newly proposed one , this experimental study does not seem to conduct sufficient experiments to demonstrate the advantages ( say , in terms of training efficiency & the capability in making the network scalable for more challenging dataset ) of the proposed objective function over the existing one ; 2 . Table 1 compares the proposed method with ODIN . However , as indicated in this work , ODIN is trained with in-domain examples only . Is this comparison fair ? Actually , ODIN 's setting seems to be more practical and more challenging than the setting used by the propose methods . 3 . The evaluation criteria shall be better explained at the beginning of the experiment , especially how they can be collectively used to verify that the proposed method can better distinguish distributional uncertainty from other uncertainty types . 4 . In addition , the experimental study can be clearer on the training and test splits . How many samples from CIFAR-10 and CIFAR-100 are used for training and test purpose , respectively ? Also , since training examples are from CIFAR-10 and CIFAR-100 and the test examples are also from these two datasets , does this contradict with the motivation of “ distributional mismatch between training and test examples ” mentioned in the abstract ? 5 . The experimental study can have more comparison on challenging datasets with more classes since it is indicated that DPN has difficulty in dealing with a large number of classes . Minor : 1 . Please define the \hat\theta in Eq . ( 5 ) . Also , is the dirac delta estimation a good enough approximation here ? 2 . The \lambda_ { out } < \lambda_ { in } in Eq . ( 11 ) needs to be better explained . In particular , are the first terms in Eq . ( 10 ) and Eq . ( 11 ) comparable in terms of magnitude ? Otherwise , \lambda_ { out } < \lambda_ { in } may not make sense . 3 . The novelty and significance of fine-tuning the proposed model with noisy OOD training images can be better justified .
Summary : This paper proposes a new approach to tackle the problem of prediction under the shift in design , which consists of the shift in policy ( conditional distribution of treatment given features ) and the shift in domain ( marginal distribution of features ) . Given labeled samples from a source domain and unlabeled samples from a target domain , this paper proposes to minimize the risk on the target domain by jointly learning the shift-invariant representation and the re-weighting function for the induced representations . According to Lemma 1 and its finite sample version in Theorem 1 , the risk on the target domain can be upper bounded by the combination of 1 ) the re-weighted empirical risk on the source domain ; and 2 ) the distributional discrepancy between the re-weighted source domain and the target domain . These theoretical results justify the objective function shown in Equation 8 . Experiments on the IHDP dataset demonstrates the advantage of the proposed approach compared to its competing alternatives . Comments : 1 ) This paper is well motivated . For the task of prediction under the shift in design , shift-invariant representation learning ( Shalit 2017 ) is biased even in the inifite data limit . On the other hand , although re-weighting methods are unbiased , they suffer from the drawbacks of high variance and unknown optimal weights . The proposed approach aims to overcome these drawbacks . 2 ) The theoretical results justify the optimization procedures presented in section 5 . Experimental results on the IHDP dataset confirm the advantage of the proposed approach . 3 ) I have some questions on the details . In order to make sure the second equality in Equation 2 holds , p_mu ( y|x , t ) = p_pi ( y|x , t ) should hold as well . Is this a standard assumption in the literature ? 4 ) Two drawbacks of previous methods motivate this work , including the bias of representation learning and the high variance of re-weighting . According to Lemma 1 , the proposed method is unbiased for the optimal weights in the large data limit . However , is there any theoretical guarantee or empirical evidence to show the proposed method does not suffer from the drawback of high variance ? 5 ) Experiments on synthetic datasets , where both the shift in policy and the shift in domain are simulated and therefore can be controlled , would better demonstrate how the performance of the proposed approach ( and thsoe baseline methods ) changes as the degree of design shift varies . 6 ) Besides IHDP , did the authors run experiments on other real-world datasets , such as Jobs , Twins , etc ?
The paper proposes a graph neural network based method to solve the retrosynthesis prediction problem , that is the identification of the reactions which lead to a particular target . In particular , the proposed graphical model exploit ideas from graph neural networks , in order to learn informative representation . Furthermore , expert knowledge from chemistry rules can be integrated in order to consider known restrictions and to provide interpretable solutions . The paper well describes the background and task of interest . However , I find the notation and model derivations to be hard to follow . The results show very promising performances , but could be more comprehensive and I find the methodological contribution to be limited . Detailed comments are provided below . 1 ) Overall , I found the model design choices to be not properly justified . I would suggest to clarify the arguments and formula derivations in section 4 , in order to make the text smoother and easier to follow . 2 ) I would also recommend to properly introduce the notation and definitions before presenting the model . 3 ) Graph Neuralization . The design and model choices seem to be arbitrary . Could the author ( s ) discuss further on it ? 4 ) Since the paper seems to be heavily focused on the application and the strong experimental results , I would suggest to explore additional options for the update operator of the graph neural network ( additionally to structure2vec ) . This would validate the actual benefit of the learning component . 5 ) Using only one dataset is restrictive in order to assess the generalisability of the method . I would consider to validate the model on additional real and/or simulated datasets % % % % % % % % % % % % % % % Thank you for your rebuttal and for answering my concerns . I found the new experiments and arguments provided to be convincing .
Summary : This paper proposes an encoder-decoder framework for learning latent representations of sets of elements . The model utilizes the neural attention mechanism for set inputs proposed in ( Vinyals et al. , ICLR 2016 ) to encode a set into a fixed-length latent representation , and then employs an LSTM decoder to reconstruct the original set of elements , in which a stable matching algorithm is used to match decoder outputs to input elements . Experimental results on synthetic datasets show that the model learns meaningful representations and effectively handles permutation invariance . Major Concerns : 1 . Although the employed Gale-Shapely algorithm facilitates permutation-invariant set reconstruction , it has O ( n^2 ) computational complexity during each back-propagation iteration , which might prevent it from scaling to sets of fairly big sizes . 2 . The experiments are only evaluated on synthetic datasets , and applications of the set autoencoder to real-world applications or scientific problems will make this work more interesting and significant . 3 . The main contribution of this work is the adoption of the stable matching algorithm in the decoder . A strong set autoencoder baseline will be , the encoder employs the neural attention mechanism proposed in ( Vinyals et al. , ICLR 2016 ) , but the decoder just uses a standard LSTM as in a seq2seq framework . Comparisons to this baseline will reveal the contribution of the stable matching procedure in the whole framework of the set autoencoder for learning representations . Minor issues : On page 5 , above Section 4 , d_j - > o_j ? the footnote on page 5 : we not consider - > we do not consider ? on page 6 and 7 , 6.000 , 1.000 and 10.000 training examples - > 6000 , 1000 and 10,000 training examples
The authors present sharp criteria for l_1-sparse support recovery under small noise in the context of non-smooth regression losses l_\infty and l_1 . Traditionally , the problem studied in support recovery left the loss shape fixed at MSE ( l2^2 ) loss and explored different non-smooth penalties , starting from the work of Fuchs on l1 penalty up until the recent , possibly most general partly smooth penalties of Vaiter et al . In the present contribution , the authors keep the simple l1 penalty but explore the effect of changing the loss function . Concretely , two loss functions , l_\infty and l_1 are studied . Both share the characteristic of being polyhedral . A proof for both cases is given , along with some confirmatory experimental results . This paper presents a new angle of generalization of the l_1 support recovery criteria to other types of loss functions , which are generally useful in regression : l_\infty corresponds to a uniform noise assumption , whereas l_1 corresponds to a sparse noise assumption . In performing this generalization , it exhibits the functionality of some quantities also obtained in the classic MSE + l1 setting , but which at the time were too specific to be given names . We thus have a non-trivial step forward in the understanding of the mechanisms involved . The proofs in the main paper are sound . However , my main comments concern the readability of this contribution . This paper took me by far the longest to review , because while mathematically perfectly rigorous , it is as if the authors a ) underestimate the fact that their contribution is some non-trivial convex analysis , that they b ) do not seem to be interested in making any concessions to the reader by providing their own intuitions or figures elucidating them and c ) that this may lead to reviews that completely miss the point of the paper . Specifically , my points are * It would be great to have a small diagram explaining the regression problem in 1D or 2D , especially since l_1 and l_\infty losses are equal , resp . equivalent in these two settings . There is sufficient space to add this without deleting anything . * up until a certain point in the paper , the paper works with general dual pairs \alpha , \beta whose harmonic mean is 1 . At some point this specializes to the polyhedral losses and later in the paper specializes to the l_\infy loss ( l1 in supp mat ) . These transitions have to be made more clear . It would be helpful also to state what intuitions are needed to keep the general ( \alpha , \beta ) ( i.e . \alpha \in ( 1 , \infty ) is not polyhedral so the proof is different , but here is how you would go about it , but here is why we do n't do this in this paper ) . * In general , the first reading of this paper is difficult , because many notations are introduced a posteriori . One arrives at table 1 and spends some time looking for definitions of \tilde\Phi and S . These are introduced in the lines below . Then one assumes |S| = |J| , which seems surprising , and is referred forward to Lemma 2 for discussion , instead of giving a quick intuition that this is not only `` for simplicity '' but even `` almost surely holds '' in a probabilistic setting and is a reasonable assumption , before referring to the details mentioned in lemma 2 . There are also several formulae which introduce a symbol and state in the next lines `` , where [ symbol ] means [ meaning ] '' . Could these be put before the formula ? * l120 concerning the situation where I ! = J , there is also [ Tibshirani , The Lasso problem and uniqueness ] . While the paper seems to state something that is implicit in many previous contributions , it would be worth being a little more explicit in how these relate * It took me 3 readings to see the bold r in regularization in l139 to make the link to FO_r . Please introduce explicitly FO_r and FO_\beta . Additionally , it would be helpful to make it a bit clearer , by adding an intermediate step , what `` corresponds '' means in l139 . Not all readers are versed enough in convex duality to read this easily . In general , since there still remains half a page of space , a way of obtaining the Fenchel dual ( e.g . by introducing the lagrangian , splitting primal variables and minimizing it wrt both of them ) and first order conditions could also be given . * It would be great to have a bit more intuition on the Lagrange multipliers v_\beta ( and some more intuition on p_\beta can be helpful too ) . In which space do they live ( the same as x resp . same as y ) . How can one imagine them geometrically ? The polytope defined by the regression constraint is difficult to untangle in the space of x , since one does n't know which constraints are active . This polytope is an intersection of seminorm balls , which could even be illustrated in 2D . Diagrams , although not easy to make , would help readers enormously . * between line 189 and 190 , does it have to be p_ { 1 , S } ? Minor * l192 `` So now , `` - > `` Now `` * l194 hypotheses - > hypothesis * between l200 and l201 put a word between the formulas `` or the second line which implies the first by operator inequality '' * l202 get - > obtain * l207 get - > obtain * l248 exceeds - > exceed * l255 theoertical -
The paper proposes a framework for learning with rejection using ideas from adversarial examples . The essential idea is , while predicting on a point x , we can reject classifying the point if it has an adversarial example very close to it . So , the algorithm can be simply summarized as , 1 . Learn a classifier function f 2 . On the test set , predict on a point , only if it does n't have an adversarial example close by . I am inclined to reject the paper for the following reasons : 1 . The proposed approach is a variation of a fairly well-known heuristic . Having a close adversarial example is same as saying that the current point is very close to the decision boundary . Being close to the decision boundary is a heuristic that has been applied in multiple scenarios in machine learning . 2 . The proposed approach is not novel . For example , [ 1 ] uses adversarial example style detection to augment their training data and improve their end-to-end model . 3 . There have been approaches which attempt to learn rejection function [ 2 ] , so it would have been good to at least do a comparison of the proposed approach with such methods . [ 1 ] Adversarial Examples For Improving End-to-End Attention-based Small-Footprint Keyword Spotting , ICASSP 2019 [ 2 ] SelectiveNet : A Deep Neural Network with an Integrated Reject Option , ICML 2019 -- - Thanks for the rebuttal . I have raised my scores , but I still believe that this paper falls short of acceptance .
The paper studies the following problem . There is a bag of infinite coins where if you draw a coin it either has bias \theta_0 with probability \alpha or \theta_1 < \theta_0 with probability 1-\alpha . In each step you either retoss the previous coin or draw a fresh coin . The goal is to find a coin with bias \theta_0 with probability 1-\delta and minimize the number of coin tosses in the process . Previous literature - When the exact values of \alpha , \theta_0 , \theta_1 are known tight bounds on number of coin tosses was previously known . Additionally this algorithm can have more than 1 coin out of the bag . Contributions of the paper - The paper gives the following two results . a ) It gives an algorithm for the setting when ( \alpha , \theta_0 , \theta_1 ) are known . It gives an adaptive strategy algorithm ( where the number of times the current coin is tosses is adaptively chosen ) which achieves the same bounds as the algorithm which knows ( \alpha_0 , \theta_0 , \theta_1 ) ( upto log factor ) . The algorithm is non-trivial . b ) The paper also shows a lower bound for class of non-adaptive algorithms which first toss N coins m times , estimate ( \alpha , \theta_0 , \theta_1 ) from these and then run the previous algorithm which assumes knowledge of ( \alpha_0 , \theta_0 , \theta_1 ) . They show that such algorithms require quadratically more number of tosses than adaptive algorithms . Nice theoretical work . A bit more details on applications will strengthen the paper further .
This work apply the wait-k decoding policy on the 2D CNN-based architecture and transformer . In the transformer-based model the author proposed to recalculate the decoder hidden states when a new source token arrives . The author also suggested to train with multiple k at the decoder level with shared encoder output . The experiments showed that the transformer model provide the best quality on IWSLT14 En-De , De-En , and WMT15 De-EN . The masking and using causal attention for the transformer has been proposed in previous works . The hidden state updates provide some gains for the model but also makes the decoder more expensive . The training with multiple k provides similar gain as training with one k larger than the value used at the inference time . Overall the contributions are limited . There is quite some room for this paper to improve its clarify , especially in terms of annotations and explaining the proposed ideas .